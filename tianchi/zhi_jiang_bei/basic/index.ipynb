{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Zero-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAP模型\n",
    "\n",
    "《Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer》\n",
    "\n",
    "典型的DAP模型具有三层结构，第一层为原始输入层，第二层为P维特征空间，第三层是输出层，输出模型对样本类别的判断\n",
    "\n",
    "## ALE模型\n",
    "\n",
    "《Label-Embedding for Attribute-Based Classification》\n",
    "\n",
    "## SAE模型\n",
    "\n",
    "《Semantic Autoencoder for Zero-Shot learning》\n",
    "\n",
    "## SCoRE\n",
    "\n",
    "《Semantically Consistent Regularization for Zero-Shot Recognition》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全局属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = r'D:\\softfiles\\workspace\\games\\zhi_jiang\\original_data'\n",
    "path_train = os.path.join(path_root, 'DatasetA_train_20180813')\n",
    "save_dir = r'D:\\softfiles\\workspace\\games\\zhi_jiang\\model'\n",
    "path_train_with_numpy = r'D:\\softfiles\\workspace\\games\\zhi_jiang\\preprocess_data'\n",
    "model_dir = r'D:\\softfiles\\workspace\\games\\zhi_jiang\\model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.layers import Dense, Flatten, Embedding, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import vgg19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = vgg19.VGG19(include_top=False, weights=None, input_shape=(64, 64, 3))\n",
    "\n",
    "# FNet\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(2048, activation='sigmoid', name='fc6')(x)\n",
    "x = Dense(2048, activation='sigmoid', name='fc7')(x)\n",
    "\n",
    "# Fnet\n",
    "model_fnet = Model(inputs=base_model.input, outputs=x)\n",
    "# model_fnet.summary()\n",
    "\n",
    "# ENet\n",
    "x = model_fnet.output\n",
    "x = Dense(30, activation='sigmoid', name='enet')(x)\n",
    "model_enet = Model(inputs=model_fnet.input, outputs=x)\n",
    "# model_enet.summary()\n",
    "\n",
    "model_enet.compile(optimizer='adam', loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30576 samples, validate on 7645 samples\n",
      "Epoch 1/10\n",
      "18688/30576 [=================>............] - ETA: 3:20 - loss: 0.0911 - acc: 0.0490"
     ]
    }
   ],
   "source": [
    "train_x = np.load(os.path.join(path_train_with_numpy, 'train_x.npy'))\n",
    "train_x = train_x / 225\n",
    "train_y = np.load(os.path.join(os.path.join(path_train_with_numpy, 'train_y.npy')))\n",
    "                  \n",
    "model_enet.fit(train_x, train_y,\n",
    "               batch_size=128,\n",
    "               epochs=10,\n",
    "               validation_split=0.2,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有图片保存成（，64， 64， 3）\n",
    "from PIL import Image\n",
    "# temp_list = ['0080ff711d1aff18b8f46ee25f686bbd.jpeg', 'd1f11b84f776416bd87b93ee6b2f7698.jpeg']\n",
    "\n",
    "path_train_image = os.path.join(path_train, 'train')\n",
    "\n",
    "train_x_np = np.zeros((len(train_x_n), 64, 64, 3), dtype='float32')\n",
    "val_x_np = np.zeros((len(val_x_n), 64, 64, 3), dtype='float32')\n",
    "\n",
    "for i, fpath in enumerate(train_x_n):\n",
    "    with Image.open(os.path.join(path_train_image, fpath)) as f:\n",
    "        if f.mode != 'RGB':\n",
    "            f = f.convert('RGB')\n",
    "        train_x_np[i] = np.asarray(f, dtype='float32')\n",
    "        \n",
    "for i, fpath in enumerate(val_x_n):\n",
    "    with Image.open(os.path.join(path_train_image, fpath)) as f:\n",
    "        if f.mode != 'RGB':\n",
    "            f = f.convert('RGB')\n",
    "        val_x_np[i] = np.asarray(f, dtype='float32')\n",
    "\n",
    "# train_y\n",
    "train_y_np = np.zeros((len(train_y_n), 30), dtype='float32')\n",
    "val_y_np = np.zeros((len(val_y_n), 30), dtype='float32')\n",
    "\n",
    "for i, label in enumerate(train_y_n):\n",
    "    train_y_np[i] = np.asarray(attribute_per_class.loc[label])\n",
    "    \n",
    "for i, label in enumerate(val_y_n):\n",
    "    val_y_np[i] = np.asarray(attribute_per_class.loc[label])\n",
    "    \n",
    "# 把train_x, train_y 保存成npy格式\n",
    "np.save(os.path.join(path_train_with_numpy, 'train_x.npy'), train_x_np)\n",
    "np.save(os.path.join(path_train_with_numpy, 'train_y.npy'), train_y_np)\n",
    "np.save(os.path.join(path_train_with_numpy, 'val_x.npy'), val_x_np)\n",
    "np.save(os.path.join(path_train_with_numpy, 'val_y.npy'), val_y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x_n, val_x_n, train_y_n, val_y_n = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7645"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_x_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类属性与类的映像model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "230/230 [==============================] - 3s 11ms/step - loss: 5.7649 - acc: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "230/230 [==============================] - 0s 418us/step - loss: 5.5580 - acc: 0.0043\n",
      "Epoch 3/2000\n",
      "230/230 [==============================] - 0s 356us/step - loss: 5.5005 - acc: 0.0043\n",
      "Epoch 4/2000\n",
      "230/230 [==============================] - 0s 408us/step - loss: 5.4842 - acc: 0.0043\n",
      "Epoch 5/2000\n",
      "230/230 [==============================] - 0s 360us/step - loss: 5.4811 - acc: 0.0043\n",
      "Epoch 6/2000\n",
      "230/230 [==============================] - 0s 459us/step - loss: 5.4795 - acc: 0.0043\n",
      "Epoch 7/2000\n",
      "230/230 [==============================] - 0s 487us/step - loss: 5.4819 - acc: 0.0043\n",
      "Epoch 8/2000\n",
      "230/230 [==============================] - 0s 418us/step - loss: 5.4772 - acc: 0.0043\n",
      "Epoch 9/2000\n",
      "230/230 [==============================] - 0s 462us/step - loss: 5.4761 - acc: 0.0043\n",
      "Epoch 10/2000\n",
      "230/230 [==============================] - 0s 513us/step - loss: 5.4747 - acc: 0.0087\n",
      "Epoch 11/2000\n",
      "230/230 [==============================] - 0s 373us/step - loss: 5.4778 - acc: 0.0043\n",
      "Epoch 12/2000\n",
      "230/230 [==============================] - 0s 416us/step - loss: 5.4747 - acc: 0.0043\n",
      "Epoch 13/2000\n",
      "230/230 [==============================] - 0s 412us/step - loss: 5.4739 - acc: 0.0000e+00\n",
      "Epoch 14/2000\n",
      "230/230 [==============================] - 0s 390us/step - loss: 5.4720 - acc: 0.0043\n",
      "Epoch 15/2000\n",
      "230/230 [==============================] - 0s 496us/step - loss: 5.4730 - acc: 0.0043\n",
      "Epoch 16/2000\n",
      "230/230 [==============================] - 0s 347us/step - loss: 5.4694 - acc: 0.0043\n",
      "Epoch 17/2000\n",
      "230/230 [==============================] - 0s 412us/step - loss: 5.4665 - acc: 0.0043\n",
      "Epoch 18/2000\n",
      "230/230 [==============================] - 0s 423us/step - loss: 5.4687 - acc: 0.0043\n",
      "Epoch 19/2000\n",
      "230/230 [==============================] - 0s 526us/step - loss: 5.4691 - acc: 0.0043\n",
      "Epoch 20/2000\n",
      "230/230 [==============================] - 0s 440us/step - loss: 5.4634 - acc: 0.0000e+00\n",
      "Epoch 21/2000\n",
      "230/230 [==============================] - 0s 397us/step - loss: 5.4612 - acc: 0.0043\n",
      "Epoch 22/2000\n",
      "230/230 [==============================] - 0s 377us/step - loss: 5.4600 - acc: 0.0043\n",
      "Epoch 23/2000\n",
      "230/230 [==============================] - 0s 455us/step - loss: 5.4558 - acc: 0.0043\n",
      "Epoch 24/2000\n",
      "230/230 [==============================] - 0s 423us/step - loss: 5.4553 - acc: 0.0043\n",
      "Epoch 25/2000\n",
      "230/230 [==============================] - 0s 453us/step - loss: 5.4543 - acc: 0.0043\n",
      "Epoch 26/2000\n",
      "230/230 [==============================] - 0s 472us/step - loss: 5.4540 - acc: 0.0000e+00\n",
      "Epoch 27/2000\n",
      "230/230 [==============================] - 0s 410us/step - loss: 5.4510 - acc: 0.0043\n",
      "Epoch 28/2000\n",
      "230/230 [==============================] - 0s 412us/step - loss: 5.4506 - acc: 0.0087\n",
      "Epoch 29/2000\n",
      "230/230 [==============================] - ETA: 0s - loss: 5.4486 - acc: 0.0063    - 0s 427us/step - loss: 5.4466 - acc: 0.0043\n",
      "Epoch 30/2000\n",
      "230/230 [==============================] - 0s 395us/step - loss: 5.4471 - acc: 0.0043\n",
      "Epoch 31/2000\n",
      "230/230 [==============================] - 0s 388us/step - loss: 5.4452 - acc: 0.0043\n",
      "Epoch 32/2000\n",
      "230/230 [==============================] - 0s 438us/step - loss: 5.4439 - acc: 0.0000e+00\n",
      "Epoch 33/2000\n",
      "230/230 [==============================] - 0s 520us/step - loss: 5.4417 - acc: 0.0087\n",
      "Epoch 34/2000\n",
      "230/230 [==============================] - 0s 515us/step - loss: 5.4404 - acc: 0.0043\n",
      "Epoch 35/2000\n",
      "230/230 [==============================] - 0s 461us/step - loss: 5.4404 - acc: 0.0043\n",
      "Epoch 36/2000\n",
      "230/230 [==============================] - 0s 369us/step - loss: 5.4360 - acc: 0.0000e+00\n",
      "Epoch 37/2000\n",
      "230/230 [==============================] - 0s 474us/step - loss: 5.4338 - acc: 0.0043\n",
      "Epoch 38/2000\n",
      "230/230 [==============================] - 0s 440us/step - loss: 5.4322 - acc: 0.0043\n",
      "Epoch 39/2000\n",
      "230/230 [==============================] - 0s 425us/step - loss: 5.4281 - acc: 0.0087\n",
      "Epoch 40/2000\n",
      "230/230 [==============================] - 0s 390us/step - loss: 5.4283 - acc: 0.0043\n",
      "Epoch 41/2000\n",
      "230/230 [==============================] - 0s 403us/step - loss: 5.4298 - acc: 0.0087\n",
      "Epoch 42/2000\n",
      "230/230 [==============================] - 0s 392us/step - loss: 5.4261 - acc: 0.0087\n",
      "Epoch 43/2000\n",
      " 32/230 [===>..........................] - ETA: 0s - loss: 5.3875 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "att_input = Input(shape=(30,))\n",
    "att_x = Dense(128, activation='sigmoid', name='att_fc1')(att_input)\n",
    "att_x = Dense(256, activation='sigmoid', name='att_fc2')(att_x)\n",
    "att_pred = Dense(230, activation='softmax', name='att_output')(att_x)\n",
    "\n",
    "att_model = Model(inputs=att_input, outputs=att_pred)\n",
    "att_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "att_model_name = 'zsc_att_model.{epoch:03d}.h5'\n",
    "att_model_filepath = os.path.join(save_dir, att_model_name)\n",
    "att_checkpoint = ModelCheckpoint(filepath=att_model_filepath,\n",
    "                                 monitor='acc',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True)\n",
    "att_callbacks = [att_checkpoint]\n",
    "\n",
    "att_train_x = np.asarray(attribute_per_class.loc[:,:]).astype('float32')\n",
    "att_train_y_label = np.asarray(attribute_per_class.index)\n",
    "att_train_y = to_categorical(range(len(att_train_y_label)))\n",
    "\n",
    "att_model.fit(att_train_x, att_train_y, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_model.save(os.path.join(model_dir, 'att_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  0.  0.  0.  0.5 0.5 0.  0.5 0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.5 0.  0.  0.5 0.  0.5 0.  0.  0.  0.  0.  0. ]]\n",
      "[[1.  0.  0.  0.  0.  0.  0.6 0.5 0.  0.5 0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.5 0.  0.  0.5 0.  0.5 0.  0.  0.  0.  0.  0. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ZJL240'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# att_model测试\n",
    "temp_test = np.asarray(attribute_per_class.loc['ZJL240']).astype('float32')\n",
    "temp_test = np.expand_dims(temp_test, 0)\n",
    "print(temp_test)\n",
    "temp_test[0,6] = 0.6\n",
    "print(temp_test)\n",
    "args = np.argmax(att_model.predict(temp_test))\n",
    "att_train_y_label[args]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取label_list\n",
    "label_list = {'ZJL1': 'goldfish','ZJL10': 'tarantula','ZJL100': 'drumstick'...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有230个类别\n"
     ]
    }
   ],
   "source": [
    "label_list = {}\n",
    "with open(os.path.join(path_train, 'label_list.txt'), 'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        label_id, label_name = line.strip().decode().split()\n",
    "        label_list[label_id] = label_name\n",
    "print('共有%s个类别' % len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取attribute list\n",
    "```python\n",
    "attribute_list = ['is animal','is transportation','is clothes'...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个类别共有30个属性\n"
     ]
    }
   ],
   "source": [
    "attribute_list = []\n",
    "with open(os.path.join(path_train, 'attribute_list.txt'), 'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        _, attribute_name = line.strip().decode().split('\\t')\n",
    "        attribute_list.append(attribute_name)\n",
    "print('每个类别共有%s个属性' % len(attribute_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取每个类别对应的属性编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "temp_head = attribute_list.copy()\n",
    "temp_head.insert(0, 'label')\n",
    "attribute_per_class = pd.read_csv(os.path.join(path_train, 'attributes_per_class.txt'),\n",
    "                                  sep='\\t', names=temp_head, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取训练图片路径和label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共训练38221张图片。\n",
      "训练数据有190个类别。\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = [], []\n",
    "with open(os.path.join(path_train, 'train.txt'), 'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        temp_path, temp_label = line.strip().decode().split('\\t')\n",
    "        train_x.append(temp_path)\n",
    "        train_y.append(temp_label)\n",
    "print('共训练%s张图片。' % len(train_x))\n",
    "print('训练数据有%s个类别。' % len(set(train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
